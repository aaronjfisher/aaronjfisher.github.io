<?xml version="1.0" encoding="utf-8"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom"><channel><title>Aaron Fisher</title><link>http://aaronjfisher.github.io/</link><description></description><atom:link href="http://aaronjfisher.github.io/feeds/all.rss.xml" rel="self"></atom:link><lastBuildDate>Sat, 03 Sep 2016 00:00:00 -0400</lastBuildDate><item><title>Why statistics professors should grade for craftsmanship</title><link>http://aaronjfisher.github.io/grade-for-craft.html</link><description>&lt;p&gt;Like many mathematical topics, statistics can be persistently abstract and unintuitive. From dividing by n-1 instead of n, to proving results in infinite dimensional Hilbert spaces, statistics rarely goes down smooth on the first try. Most of the best statisticians take this challenge head on. They can quickly distill the intuition behind bafflingly abstract ideas, either to readers, students, or collaborators. Our community rewards this type of explanatory skill over the timespan of a career, but we put little value on it when grading students. Students are typically graded for correctness, completeness, and (sometimes) participation, but not for craftsmanship. That's a missed opportunity.&lt;/p&gt;
&lt;p&gt;Over a career, statisticians who explain abstract concepts well will do better on the job market, be invited to give more talks, get better teaching reviews by students (all else equal), and will attract more students to do research with. Ultimately, they'll also get more scientists using their tools.&lt;/p&gt;
&lt;p&gt;From the educational perspective, &lt;a href="https://medium.com/@jeremyjkun/habits-of-highly-mathematical-people-b719df12d15e#.mb6fo9nv8" target="_blank"&gt;Jeremy Kun recently wrote a great piece&lt;/a&gt; on the habits of mathematical people, and why math education should be seen as a core tenant of training well-rounded adults. Knowing how an algorithm works does more than train us in how to use it, or how to “go under the hood” when it breaks down. Kun argues that it trains us to be conscious of our assumptions, to concretely define terms, and to admit when we're wrong. On top of this, working in a field that requires you to "spend almost all of your time understanding nothing" can hopefully imbue a kind of emotional resilience. To be successful, you have to be able to endure your own confusion until a blip of understanding seeps through. &lt;a href="https://medium.com/@gauravkulkarni/the-importance-of-learning-math-and-science-a62e220623f5#.39nlnrw0d" target="_blank"&gt;Gaurav Kulkarni argues&lt;/a&gt; that math and science teaches students to embrace the unintuitive, and to expect real life systems to be complex rather than tweetable. I would add on to this that, at its best, mathematics doesn't just train us to understand and explain abstract concepts correctly, it trains us to explain them artfully.&lt;/p&gt;
&lt;p&gt;Perhaps we should better reflect this in how we evaluate statistics students. On homeworks and exams, correctness should take priority, but the craft of an argument's construction has value too.&lt;/p&gt;
&lt;p&gt;One approach here is to treat craftsmanship in a similar way to class participation. Another partial solution could be to require a certain level of clarity and formatting polish in write-ups. While polish is certainly not the same as skillful explanation, it does focus more attention on the presentation and can be a push in the right direction.&lt;/p&gt;
&lt;p&gt;Beyond this, balancing craftsmanship with correctness becomes a problem of limited time and resources, much like balancing the scope and depth of a course's topic load. From a student's perspective, improving a write-up's presentation cannot be done without sacrificing time or completeness. From an instructor's perspective though, prioritizing clarity, brevity and craftsmanship can increase resources by saving hours of grading time. Depending on the course, it may be helpful to put more focus on craftsmanship. Less topics would be covered, but it could also lead to more well-rounded students, and faster proliferation of statistical breakthroughs.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Author's note: I started thinking about this after a &lt;a href="https://www.amstat.org/meetings/jsm/2016/onlineprogram/ActivityDetails.cfm?SessionID=212487" target="_blank"&gt;seminar session on the Julia programming language&lt;/a&gt; during this year's JSM conference. It was, by far, the most eloquent set of talks I saw. One highlight was &lt;a href="http://www.slideshare.net/acidflask/julia-genomics-data-and-their-principal-components" target="_blank"&gt;a talk&lt;/a&gt; by Jiahao Chen, who referenced the Sapir-Whorf hypothesis that language shapes our cognition – with a more elegant language, we can write more elegant algorithms. It should not have been surprising that people who think about languages all day tend to also be darn good speakers.&lt;/em&gt; &lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Fisher</dc:creator><pubDate>Sat, 03 Sep 2016 00:00:00 -0400</pubDate><guid>tag:aaronjfisher.github.io,2016-09-03:grade-for-craft.html</guid><category>communication</category><category>language</category><category>best practices</category><category>education</category></item><item><title>Mark Twain was a stats fan, anything else is a Damn Lie.</title><link>http://aaronjfisher.github.io/mark-twain-was-a-stats-fan.html</link><description>&lt;p&gt;At some point or another, many of us have heard the quote popularized by Mark Twain, that "there are three kinds of lies: lies, damned lies, and statistics." For a long time, my response was to snarkily question Twain's statistical training -- I would say that he was writing about something beyond his qualifications (but what did I know, I'm not a writer). It turns out though that &lt;strong&gt;Twain's comment was not meant as an attack on overly complicated statistical wizardry that obfuscates the truth. If you read the quote in context, his point is actually quite the opposite.&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Here's an extended quote from &lt;a href="http://www.gutenberg.org/files/19987/19987-h/19987-h.htm" target="_blank"&gt;his autobiography&lt;/a&gt;, in all of it's wordy glory. In it he describes the speed of his writing process at different points in his life.&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;I was very young in those days, exceedingly young, marvelously young, younger than I am now, younger than I shall ever be again, by hundreds of years. I worked every night from eleven or twelve until broad day in the morning, and as I did two hundred thousand words in the sixty days, the average was more than three thousand words a day -— nothing for Sir Walter Scott, nothing for Louis Stevenson, nothing for plenty of other people, but quite handsome for me. In 1897, when we were living in Tedworth Square, London, and I was writing the book called "Following the Equator" my average was eighteen hundred words a day; here in Florence (1904), my average seems to be fourteen hundred words per sitting of four or five hours.&lt;/p&gt;
&lt;p&gt;I was deducing from the above that I have been slowing down steadily in these thirty-six years, but I perceive that my statistics have a defect: three thousand words in the spring of 1868 when I was working seven or eight or nine hours at a sitting has little or no advantage over the sitting of to-day, covering half the time and producing half the output. Figures often beguile me, particularly when I have the arranging of them myself; in which case the remark attributed to Disraeli would often apply with justice and force:&lt;/p&gt;
&lt;p&gt;"There are three kinds of lies: lies, damned lies, and statistics."&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;It's beautifully humble, in a few ways. Twain says that when he first looked back on his daily word output over the years, it seemed as if he was gradually losing his edge and slowing down. When he looked closer though, he realized that he hadn't adjusted for the amount of time he spent writing &lt;em&gt;per day&lt;/em&gt;. He had the wrong denominator.&lt;/p&gt;
&lt;p&gt;To paint this graphically, when Twain looked back at his raw data, he saw a pattern of declining writing speed:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt-text" src="blog_supplements/2015-07-26-twain/twain_words_per_day.png" /&gt;&lt;/p&gt;
&lt;p&gt;But when he looked closer and adjusted for hours spent writing per day, there was practically no change at all:&lt;/p&gt;
&lt;p&gt;&lt;img alt="alt-text" src="blog_supplements/2015-07-26-twain/twain_words_per_hour.png" /&gt;&lt;/p&gt;
&lt;p&gt;Twain isn't arguing against complicated models, he's arguing against models that aren't complex enough to sufficiently interpret the data! He even goes a step further when he says "Figures often beguile me, &lt;em&gt;particularly when I have the arranging of them myself.&lt;/em&gt;" In other words, if you're in over your head, you should probably consult a statistician. &lt;/p&gt;
&lt;p&gt;After all of this time being misinterpreted, there is a part of me that likes to think Twain would be pleased to see his endorsement of rigorous statistical thinking re-expressed in base R graphics.&lt;/p&gt;
&lt;p&gt;I only recently found out about the extended quote when it was pointed out to me by &lt;a href="http://blades.byu.edu/"&gt;Natalie Blades&lt;/a&gt;, as we were teaching &lt;a href="http://www.jhsph.edu/departments/epidemiology/continuing-education/graduate-summer-institute-of-epidemiology-and-biostatistics/courses/statistical-reasoning-in-public-health-I.html"&gt;a set&lt;/a&gt; of &lt;a href="http://www.jhsph.edu/departments/epidemiology/continuing-education/graduate-summer-institute-of-epidemiology-and-biostatistics/courses/statistical.reasoning.in.public.health.II.html"&gt;statistics courses&lt;/a&gt; this summer that featured the quote. Benjamin Disraeli, the quote's originator, may have been more dismissive of statistical inference. But Twain's thinking seems to be substantially different.&lt;/p&gt;
&lt;p&gt;&lt;/br&gt;&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;########### Code for plots ###########&lt;/span&gt;

&lt;span class="c1"&gt;#### Load data&lt;/span&gt;
library&lt;span class="p"&gt;(&lt;/span&gt;RCurl&lt;span class="p"&gt;)&lt;/span&gt;
library&lt;span class="p"&gt;(&lt;/span&gt;foreign&lt;span class="p"&gt;)&lt;/span&gt;
twainDataURL &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; getURL&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;https://aaronjfisher.github.io/blog_supplements/2015-07-26-twain/twain.csv&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;                
&lt;span class="p"&gt;(&lt;/span&gt;x &lt;span class="o"&gt;&amp;lt;-&lt;/span&gt; read.csv&lt;span class="p"&gt;(&lt;/span&gt;textConnection&lt;span class="p"&gt;(&lt;/span&gt;twainDataURL&lt;span class="p"&gt;),&lt;/span&gt;header&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;


&lt;span class="c1"&gt;#### Plot 1 - words per day&lt;/span&gt;
firstplot&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;&lt;span class="kr"&gt;function&lt;/span&gt;&lt;span class="p"&gt;(){&lt;/span&gt;
    par&lt;span class="p"&gt;(&lt;/span&gt;mar &lt;span class="o"&gt;=&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;5&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
    plot&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;year&lt;span class="p"&gt;,&lt;/span&gt; x&lt;span class="o"&gt;$&lt;/span&gt;wordsPerDay&lt;span class="p"&gt;,&lt;/span&gt; type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; ylim&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; max&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;wordsPerDay&lt;span class="p"&gt;)),&lt;/span&gt; 
        main&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;quot;Mark Twain&amp;#39;s Writing Speed&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; ylab&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
        xlab&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;year&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;darkred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lwd&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; lty&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
    mtext&lt;span class="p"&gt;(&lt;/span&gt;side&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; line&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;words per day&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;span class="p"&gt;}&lt;/span&gt;
firstplot&lt;span class="p"&gt;()&lt;/span&gt;

&lt;span class="c1"&gt;#### Plot 2 - words per hour&lt;/span&gt;
firstplot&lt;span class="p"&gt;()&lt;/span&gt;

par&lt;span class="p"&gt;(&lt;/span&gt;new&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
skip&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;is.na&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;hrsPerDay&lt;span class="p"&gt;)&lt;/span&gt;
ylim2&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;0&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="o"&gt;*&lt;/span&gt;max&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;wordsPerDay&lt;span class="o"&gt;/&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;hrsPerDay&lt;span class="p"&gt;,&lt;/span&gt; na.rm&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;
plot&lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;year&lt;span class="p"&gt;[&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;skip&lt;span class="p"&gt;],&lt;/span&gt; &lt;span class="p"&gt;(&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;wordsPerDay&lt;span class="o"&gt;/&lt;/span&gt;x&lt;span class="o"&gt;$&lt;/span&gt;hrsPerDay&lt;span class="p"&gt;)[&lt;/span&gt;&lt;span class="o"&gt;!&lt;/span&gt;skip&lt;span class="p"&gt;],&lt;/span&gt; 
    type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;o&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; axes&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;FALSE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; xlab&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;NA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; ylab&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;NA&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; col&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;darkblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; 
    lwd&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; ylim&lt;span class="o"&gt;=&lt;/span&gt;ylim2&lt;span class="p"&gt;,&lt;/span&gt; lty&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
axis&lt;span class="p"&gt;(&lt;/span&gt;side&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
mtext&lt;span class="p"&gt;(&lt;/span&gt;side&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;4&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; line&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2.5&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;quot;words per hour&amp;quot;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

legend&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;bottomleft&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;words per day&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;words per hour&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    col&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;darkred&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="s"&gt;&amp;#39;darkblue&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; lty&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; &lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; lwd&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt; pch&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Fisher</dc:creator><pubDate>Sun, 26 Jul 2015 00:00:00 -0400</pubDate><guid>tag:aaronjfisher.github.io,2015-07-26:mark-twain-was-a-stats-fan.html</guid><category>communication</category><category>variable adjustment</category></item><item><title>Many statistical "gold standards" aren't perfect, but that's why they're perfectly named</title><link>http://aaronjfisher.github.io/gold-standards-are-not-perfect.html</link><description>&lt;p&gt;Statisticians and computer scientists often use the term "gold standard" for the best possible benchmark you could have when trying to estimate something. For example, &lt;a href="https://elizabethmargaretsweeney.wordpress.com/" target="_blank"&gt;Elizabeth Sweeney&lt;/a&gt; has worked on &lt;a href="http://www.ajnr.org/content/early/2012/07/05/ajnr.A3172.abstract" target="_blank"&gt;algorithms&lt;/a&gt; for &lt;a href="http://www.sciencedirect.com/science/article/pii/S2213158213000235" target="_blank"&gt;tagging brain lesions in MRIs&lt;/a&gt;, and compares the results against a gold standard of human neurologists attempting the same task. In clinical trials, randomized clinical trials (RCTs) are sometimes referred to a gold standard approach for estimating a treatment effect because they are more likely to account for unmeasured confounders.&lt;/p&gt;
&lt;p&gt;But in these examples and in others, &lt;a href="http://www.ncbi.nlm.nih.gov/pubmed/11700857" target="_blank"&gt;statisticians often question the benchmark's "gold standard" status,&lt;/a&gt; saying something the lines of "it's not really a gold standard" because &lt;a href="http://aje.oxfordjournals.org/content/145/2/184.short" target="_blank"&gt;it isn't perfect&lt;/a&gt;. Imperfect neurologists &lt;a href="http://www.neurology.org/cgi/content/meeting_abstract/78/1_MeetingAbstracts/P03.068" target="_blank"&gt;do not always agree with each other&lt;/a&gt;, are &lt;a href="http://www.sciencedirect.com/science/article/pii/S2213158213000235" target="_blank"&gt;not always even internally consistent&lt;/a&gt;.&lt;sup id="fnref:sectionRef"&gt;&lt;a class="footnote-ref" href="#fn:sectionRef" rel="footnote"&gt;1&lt;/a&gt;&lt;/sup&gt; Randomized trials help to control for unmeasured confounders over repeated trials, but are not guaranteed to do so in any one, specific trial. &lt;/p&gt;
&lt;p&gt;&lt;strong&gt;&lt;em&gt;My take is that the term "gold standard" should still apply though. More-so even, because the actual gold standard of matching currency to gold reserves isn't perfect either.&lt;/em&gt;&lt;/strong&gt;&lt;sup id="fnref:counter"&gt;&lt;a class="footnote-ref" href="#fn:counter" rel="footnote"&gt;2&lt;/a&gt;&lt;/sup&gt; It's a minor point, but a fun one that's sometimes&lt;sup id="fnref:wiki"&gt;&lt;a class="footnote-ref" href="#fn:wiki" rel="footnote"&gt;3&lt;/a&gt;&lt;/sup&gt; forgotten.&lt;/p&gt;
&lt;p&gt;This post is not meant to be political, but it's fairly well established that the gold standard has both advantages and disadvantages. Tying your currency to gold reserves helps to control inflation, but it also highly restricts your monetary policy. Prices tied to gold tend to be stable in the long run, but &lt;a href="http://krugman.blogs.nytimes.com/2012/08/26/golden-instability/?_r=0" target="_blank"&gt;not always stable&lt;/a&gt; in the &lt;a href="http://www.theatlantic.com/business/archive/2012/08/why-the-gold-standard-is-the-worlds-worst-economic-idea-in-2-charts/261552/" target="_blank"&gt;short run&lt;/a&gt;. For most mainstream economists, the connotations of the gold standard &lt;a href="http://blogs.wsj.com/ideas-market/2012/01/23/survey-no-support-for-gold-standard-among-top-economists/" target="_blank"&gt;are pretty bad&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;In some ways, gold is just another attempt at a best practice for objective value. Like paper money, it's not inherently valuable, it's only valuable by convention. In much the same way, &lt;strong&gt;when I hear the someone talk about a statistical "gold standard," I like to think of it as a subtle reminder that, for many estimation problems, even the best benchmarks aren't perfect.&lt;/strong&gt; 
&lt;br/&gt;&lt;/p&gt;
&lt;p&gt;Special thanks to economists Daniel Garcia Molina and Sohini Mahapatra for their help with this post!&lt;/p&gt;
&lt;div class="footnote"&gt;
&lt;hr /&gt;
&lt;ol&gt;
&lt;li id="fn:sectionRef"&gt;
&lt;p&gt;Within the OASIS paper, section 3.3 discusses within-rater variability, and section 3.4 discusses between-rater variability.&amp;#160;&lt;a class="footnote-backref" href="#fnref:sectionRef" rev="footnote" title="Jump back to footnote 1 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:counter"&gt;
&lt;p&gt;Of course, one counter argument is that language is defined by modern usage rather than historical meaning, the same reason that we acknowledge how "literally" can informally be used to mean "figuratively".&amp;#160;&lt;a class="footnote-backref" href="#fnref:counter" rev="footnote" title="Jump back to footnote 2 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;li id="fn:wiki"&gt;
&lt;p&gt;To some extent, this point is raised on the &lt;a href="https://en.wikipedia.org/wiki/Gold_standard_(test)" target="_blank"&gt;wikipedia page for a gold standard test&lt;/a&gt;.&amp;#160;&lt;a class="footnote-backref" href="#fnref:wiki" rev="footnote" title="Jump back to footnote 3 in the text"&gt;&amp;#8617;&lt;/a&gt;&lt;/p&gt;
&lt;/li&gt;
&lt;/ol&gt;
&lt;/div&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Fisher</dc:creator><pubDate>Thu, 23 Jul 2015 00:00:00 -0400</pubDate><guid>tag:aaronjfisher.github.io,2015-07-23:gold-standards-are-not-perfect.html</guid><category>language</category><category>benchmarks</category><category>best practices</category></item><item><title>4 minutes to run code: a live demo inside a JSM speed talk</title><link>http://aaronjfisher.github.io/JSM-2014-demo-part1.html</link><description>&lt;p&gt;&lt;em&gt;2014-08-08 Update: Added results from the presentation, and a link to run the demo on your own computer. Also added a brief summary of the intuition for the method.&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;On Monday morning, at this year's &lt;a href="http://www.amstat.org/meetings/jsm/2014/index.cfm#" target="_blank"&gt;JSM&lt;/a&gt;, I'll be presenting at the &lt;a href="http://www.amstat.org/meetings/jsm/2014/onlineprogram/ActivityDetails.cfm?SessionID=210515" target="_blank"&gt;speed talks session on Epidemiology and Imaging&lt;/a&gt;. My plan is to attempt something a little unconventional: to live demo a new method for a computationally intensive procedure (&lt;a href="http://arxiv.org/abs/1405.0922" target="_blank"&gt;bootstrap PCA&lt;/a&gt;), within a presentation that's limited to just 4 minutes.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Will the code finish in time?&lt;br&gt;Or will I epic fail in front of all my peers?&lt;/br&gt;&lt;a href="http://www.amstat.org/meetings/jsm/2014/onlineprogram/ActivityDetails.cfm?SessionID=210515" target="_blank"&gt;Stop by to find out!!!&lt;/a&gt;&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;For context, the idea of these speed sessions is to quickly show the work of a couple dozen people. Audience members get a sense of who they might like to talk to more, and can ask questions in a poster session that immediately follows the speed talks. &lt;/p&gt;
&lt;p&gt;I'll be demoing the application of a &lt;a href="http://arxiv.org/abs/1405.0922" target="_blank"&gt;fast, exact procedure for bootstrapping principal component analysis (PCA) in high dimensional samples&lt;/a&gt;. This is one way to estimate sampling variability for principal components (PCs), although it's traditionally very computationally intensive (until now!). &lt;/p&gt;
&lt;p&gt;I'll be applying the procedure to a &lt;a href="http://pics.psych.stir.ac.uk/2D_face_sets.htm" target="_blank"&gt;public dataset&lt;/a&gt; of 103 face images. Each image contains 92,036 pixels (346x266). Here are some examples of what these images look like, rendered with the &lt;code&gt;image&lt;/code&gt; function in R.&lt;/p&gt;
&lt;p&gt;&lt;img src="blog_supplements/2014-07-28_JSM-2014-demo-part1/2014-04-02_stirling_faces.png" alt="faces_ex" style="width: 100%;"/&gt;&lt;/p&gt;
&lt;p&gt;These are the first three principal components, or "eigenfaces," for the sample.&lt;/p&gt;
&lt;p&gt;&lt;img src="blog_supplements/2014-07-28_JSM-2014-demo-part1/faces_results_crop_PCs.png" alt="faces_ex" style="width: 100%;"/&gt;&lt;/p&gt;
&lt;p&gt;On Monday, I'll be trying to calculate pixel-wise bootstrap standard errors for these eigenfaces based on 1000 bootstrap samples. With standard methods this would take about 16 minutes -- way too long for a speed talk.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;2014-08-08 Updated results section:&lt;/em&gt; &lt;/br&gt;It worked!! Here are the resulting bootstrap standard errors. They took about 13 seconds to calculate.&lt;/p&gt;
&lt;p&gt;&lt;img src="blog_supplements/2014-07-28_JSM-2014-demo-part1/faces_results_crop_results.png" alt="faces_ex" style="width: 100%;"/&gt;&lt;/p&gt;
&lt;p&gt;The &lt;a href="http://arxiv.org/abs/1405.0922" target="_blank"&gt;key&lt;/a&gt; to improving the speed of the procedure is that while the sample is high dimensional (92,036 variables per observation) we can always find a low dimensional subspace (103 variables per observation) that contains all of the  sample points. This subpace also contains all bootstrap samples, as the bootstrap samples are redrawn from the original sample. If we represent bootstrap samples according to their low-dimensional coordinates, relative to this known subspace, we don't have to operate on the 92,036-dimensional data. Instead, we can just operate on it's known, 103-dimensional representation. Our method restricts as many computations as possible to this 103-dimensional subspace before projecting back to the original 92,036-dimensional space. This dramatically reduces computation time and memory requirements. &lt;/p&gt;
&lt;p&gt;This demo was created as an R package, which I loaded and ran the day of the talk. You can run this demo on your own setup very easily, by &lt;a href="https://github.com/aaronjfisher/2014_JSM_bootSVD_demo" target="_blank"&gt;running a few lines of code to download the package off github&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;&lt;em&gt;(end of 2014-08-08 update)&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;Session details:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://www.amstat.org/meetings/jsm/2014/onlineprogram/ActivityDetails.cfm?SessionID=210515" target="_blank"&gt;8:30am  - 10:20am:  Speed talks (schedule link)&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://www.amstat.org/meetings/jsm/2014/onlineprogram/ActivityDetails.cfm?SessionID=210561" target="_blank"&gt;10:30am - 11:15am: Poster session&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;/br&gt;&lt;/br&gt;
&lt;em&gt;Note: I'm applying this method to the subset of the &lt;a href="http://pics.psych.stir.ac.uk/2D_face_sets.htm" target="_blank"&gt;"stirling"&lt;/a&gt; dataset that consists of people facing the camera directly. I'm not including the profile images in this dataset.&lt;/em&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Fisher</dc:creator><pubDate>Thu, 31 Jul 2014 00:00:00 -0400</pubDate><guid>tag:aaronjfisher.github.io,2014-07-31:JSM-2014-demo-part1.html</guid><category>computing</category><category>talks</category><category>bootstrap</category></item><item><title>ggBrain - An R package for beautiful brain figures</title><link>http://aaronjfisher.github.io/ggBrain-debut.html</link><description>&lt;p&gt;Check out this lovely brain image figure! I wrote &lt;a href="https://github.com/aaronjfisher/ggBrain" target="_blank"&gt;an R package called ggBrain&lt;/a&gt; that lets you generate figures like these with just a couple lines of code!&lt;/p&gt;
&lt;p&gt;&lt;img src="blog_supplements/2014-07-24_ggBrain-debut/2014-07-30_RAVENS_PCA_saggital_fitted.png" alt="bootPCAimg" style="width: 100%;"/&gt;&lt;/p&gt;
&lt;p&gt;This figure is from my recent &lt;a href="http://arxiv.org/abs/1405.0922" target="_blank"&gt;paper on fast, exact methods for bootstrapping high dimensional data (&amp;gt;1 million measurements per subject)&lt;/a&gt;. When I was working on figures for the paper, I knew that I wanted to use ggplot, but I ended up being surprised by how much tweaking and planning was needed. To help automate the process, I wrote up an R package called &lt;a href="https://github.com/aaronjfisher/ggBrain" target="_blank"&gt;ggBrain&lt;/a&gt;, which transforms brain image arrays into ggplot objects.&lt;/p&gt;
&lt;p&gt;The main step &lt;a href="https://github.com/aaronjfisher/ggBrain" target="_blank"&gt;ggBrain&lt;/a&gt; handles is the reshaping of 3-dimensional or 4-dimensional brain image arrays into 2-dimensional, "long" data frames -- the data format required for ggplot. The generated data frames only contain information about the slices to be shown in the final figure. Index variables are included to allow the final figures to contain multiple panels (faceted figures). Panels can contain images from different slices, different time points (in fMRI), or different subjects.&lt;/p&gt;
&lt;p&gt;The package can also automate several aesthetic options, including:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Tri-planar figures:  For a given voxel, a tri-planar figure shows the sagittal, coronal, and transverse slices that intersect that voxel. These three slices are shown in three panels, and cross-hairs are generated to show the spacial correspondence between the slices (see example below).&lt;/li&gt;
&lt;li&gt;Separete fill scales for template brain images and for overlaying voxel-wise statistics: ggplot2 generally discourages the use of color to display different types of data, on different scales. This makes it hard to use color to show both a brain image template, and to show the value, or sign, of a voxel-wise statistic overlaid on top of that template (see below for an example with seed correlation). The template tissue intensities and the test statistic values are on different scales, which goes against ggplot's method of using only one scale for fill. In this package, I chose to do the quick fix of hardcoding the coloring of the template image, so that only the voxelwise statistic is formally mapped through ggplot.&lt;/li&gt;
&lt;li&gt;ggplot themes for changing the background to be black, and for removing irrelevant plot labels. &lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Examples&lt;/h2&gt;
&lt;p&gt;The vignette for &lt;a href="https://github.com/aaronjfisher/ggBrain" target="_blank"&gt;ggBrain&lt;/a&gt; (see &lt;code&gt;help(package=ggBrain)&lt;/code&gt;) contains several code examples with explanation, so I'll just give a couple brief examples here. They should give you a sense for the small amount of code required for each figure. In these code chunks, &lt;code&gt;dd&lt;/code&gt; is a standard ggplot object. Aesthetic changes are added to &lt;code&gt;dd&lt;/code&gt; using the usual ggplot syntax.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;&lt;span class="c1"&gt;# Seed correlation map (stored in the array s_map1)&lt;/span&gt;
&lt;span class="c1"&gt;# mar=3 selects the Transverse plane, and mar_ind=30 selects the slice index.&lt;/span&gt;
dd&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;ggBrain&lt;span class="p"&gt;(&lt;/span&gt;template&lt;span class="o"&gt;=&lt;/span&gt;template&lt;span class="p"&gt;,&lt;/span&gt;brains&lt;span class="o"&gt;=&lt;/span&gt;s_map1&lt;span class="p"&gt;,&lt;/span&gt;mask&lt;span class="o"&gt;=&lt;/span&gt;mask&lt;span class="p"&gt;,&lt;/span&gt;mar&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;
    mar_ind&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;signed&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt;

dd &lt;span class="o"&gt;+&lt;/span&gt; labs&lt;span class="p"&gt;(&lt;/span&gt;title&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Seed Correlation Map&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt;
    theme_black_bg&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="alt-text" src="blog_supplements/2014-07-24_ggBrain-debut/seed_map.png" /&gt;&lt;/p&gt;
&lt;p&gt;Above, the sign of the correlation is mapped to fill (with a binary scale), and the absolute value of the correlation is mapped to alpha blending (transparency). By default, &lt;a href="https://github.com/aaronjfisher/ggBrain" target="_blank"&gt;ggBrain&lt;/a&gt; bins the data in order to combine the legends for alpha blending and for fill.&lt;/p&gt;
&lt;p&gt;It's also possible to fix a constant level of alpha blending across the image, and to map the raw value of the correlation to a diverging color scale. However, I'm not a fan of the white patches in low correlation regions that result from this approach, and tend to prefer the mapping setup used above.&lt;/p&gt;
&lt;p&gt;The image below is an example of a tri-planar figure. Again, for a given voxel, a tri-planar figure shows the sagittal, coronal, and tranvserse slices that intersect that voxel. This tri-planar figure shows the seed region used to calculate the seed correlation map above.&lt;/p&gt;
&lt;div class="highlight"&gt;&lt;pre&gt;column_ind &lt;span class="o"&gt;=&lt;/span&gt; factor&lt;span class="p"&gt;(&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;labels&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Sagittal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Coronal&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Transverse&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;))&lt;/span&gt;

dd&lt;span class="o"&gt;&amp;lt;-&lt;/span&gt;ggBrain&lt;span class="p"&gt;(&lt;/span&gt;brains&lt;span class="o"&gt;=&lt;/span&gt;seed_mask&lt;span class="p"&gt;,&lt;/span&gt;template&lt;span class="o"&gt;=&lt;/span&gt;template&lt;span class="p"&gt;,&lt;/span&gt;mar&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;2&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;3&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;
    mar_ind&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;37&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;18&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;30&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt;row_ind&lt;span class="o"&gt;=&lt;/span&gt;c&lt;span class="p"&gt;(&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;&lt;span class="m"&gt;1&lt;/span&gt;&lt;span class="p"&gt;),&lt;/span&gt; col_ind&lt;span class="o"&gt;=&lt;/span&gt;column_ind&lt;span class="p"&gt;,&lt;/span&gt;
    type&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;binary&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;binary_color&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;black&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;tri_planar&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="kc"&gt;TRUE&lt;/span&gt;&lt;span class="p"&gt;,&lt;/span&gt;mask&lt;span class="o"&gt;=&lt;/span&gt;mask&lt;span class="p"&gt;)&lt;/span&gt;

dd &lt;span class="o"&gt;+&lt;/span&gt; labs&lt;span class="p"&gt;(&lt;/span&gt;alpha&lt;span class="o"&gt;=&lt;/span&gt;&lt;span class="s"&gt;&amp;#39;Seed mask&amp;#39;&lt;/span&gt;&lt;span class="p"&gt;)&lt;/span&gt; &lt;span class="o"&gt;+&lt;/span&gt; theme_black_bg&lt;span class="p"&gt;()&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;


&lt;p&gt;&lt;img alt="alt-text" src="blog_supplements/2014-07-24_ggBrain-debut/seed_mask_triplane.png" /&gt;&lt;/p&gt;
&lt;p&gt;If you're interested, please &lt;a href="https://github.com/aaronjfisher/ggBrain" target="_blank"&gt;check out the package!&lt;/a&gt;&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Fisher</dc:creator><pubDate>Wed, 30 Jul 2014 00:00:00 -0400</pubDate><guid>tag:aaronjfisher.github.io,2014-07-30:ggBrain-debut.html</guid><category>plots</category><category>brain imaging</category></item><item><title>Don't go to Hogwarts if you're into science</title><link>http://aaronjfisher.github.io/dont-go-to-hogwarts.html</link><description>&lt;p&gt;I sometimes hear people say that they wish they could've gone to Hogwarts School of Witchcraft and Wizardry (HSWW), but there’s a drawback of HSWW that's often overlooked. You can do a lot with a degree from HSWW, but the one thing that’s hard to do is to become a scientist. In fact, there's very little emphasis on science in the HSWW culture. Students learn plenty of spells and potion recipes, but nobody at the school has a good understanding of how magic actually works -- after thousands of years, they still call it magic! It’s possible that no one in the wizarding world has ever studied the mechanisms underlying magic, but I don't buy it. How could wizards have witnessed the muggle scientific revolution, and not looked at wands under a microscope? No, there must be scientific research institutions in the wizarding world too, which leads to only conclusion:&lt;/p&gt;
&lt;p&gt;&lt;em&gt;Hogwarts is a technical school.&lt;/em&gt; It's where you go to learn a craft. It's great at sports, but not so great with cutting edge research.&lt;/p&gt;
&lt;p&gt;Of course, HSWW &lt;em&gt;was&lt;/em&gt; on the front lines of preventing a global holocaust, while professors from Beauxbatons and Durmstrang Institute were off in their ivory towers, presumably debating time travel paradoxes or developing new languages for object-oriented spell casting. When shit hit the fan, HSWW stepped up. &lt;/p&gt;
&lt;p&gt;That said, there must be another school out there that’s experimenting with new yeast strains for butter-beer, and running clinical trials on healing charms. If you like science, that’s the place to be.&lt;/p&gt;
&lt;p&gt;&lt;br/&gt;&lt;br/&gt;
&lt;em&gt;Notes:&lt;/em&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;em&gt;A friend has pointed out that this post is very similar to the fan fiction work &lt;a href="http://hpmor.com/"&gt;Harry Potter and the Methods of Rationality&lt;/a&gt;, which is essentially the same joke but much more fleshed out.&lt;/em&gt;&lt;/li&gt;
&lt;li&gt;&lt;em&gt;While there's a potential analogy to black box models here, this post really doesn't have much to do with statistics. Future posts will be more relevant to stats, with high probability.&lt;/em&gt;
&lt;br/&gt;&lt;/li&gt;
&lt;/ul&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Fisher</dc:creator><pubDate>Tue, 10 Jun 2014 00:00:00 -0400</pubDate><guid>tag:aaronjfisher.github.io,2014-06-10:dont-go-to-hogwarts.html</guid><category>black-box models</category><category>humor</category></item><item><title>Mission Statement for the Blog</title><link>http://aaronjfisher.github.io/mission-statement.html</link><description>&lt;p&gt;In this blog, I'll talk about issues in statistics from a graduate student's perspective. Some specific topics include: surviving a PhD, enjoying a PhD, designing intuitive graphics, and dealing with high dimensional data. There will also be musings from time to time about food/cooking (i.e. JHSPH Biostat Chili Cookoff strategy), and culture in general.&lt;/p&gt;
&lt;p&gt;I'll try to keeps these posts clear and concise, with working code examples. &lt;/p&gt;
&lt;p&gt;Hope you enjoy!&lt;/p&gt;</description><dc:creator xmlns:dc="http://purl.org/dc/elements/1.1/">Aaron Fisher</dc:creator><pubDate>Mon, 07 Apr 2014 00:00:00 -0400</pubDate><guid>tag:aaronjfisher.github.io,2014-04-07:mission-statement.html</guid><category>blog</category></item></channel></rss>