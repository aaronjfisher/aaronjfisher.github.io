<!doctype html>
<html lang="">	
<head>
	<meta charset="utf-8"/>
	<title>Research- Aaron Fisher</title>	
	<meta name="author" content="Aaron Fisher">
	
	<link rel="top" href="#" /><link href='http://fonts.googleapis.com/css?family=Source+Sans+Pro:300,400,600,300italic,400italic,600italic|Source+Code+Pro' rel='stylesheet' type='text/css'></link>
	<link rel="stylesheet" href="https://aaronjfisher.github.io/theme/css/main.css" type="text/css" />
		

    <link href="https://aaronjfisher.github.io/feeds/all.rss.xml" type="application/rss+xml" rel="alternate" title="Aaron Fisher RSS Feed" />
</head>
	
<body>

    <div class="container">
	  <img src="../images/2013-11-17_13.53.21-noFlowers-cleanend-arrows3-crop1.png" width=100%/>
	  <header role="banner">
	      <div class="pages">
			  <a href="https://aaronjfisher.github.io/">About</a>
-			  <a href="https://aaronjfisher.github.io/pages/cv.html">CV</a>
-			  <a href="https://aaronjfisher.github.io/pages/research.html">Research</a>
-			  <a href="https://aaronjfisher.github.io/pages/contact.html">Contact</a>

			<!--  AF - Manually add some stuff that wasn't there, not including archives yet, as we really don't have enough stuff, &nbsp is a non break space, which seemed nessecary as a hack to get the banner spacing right -->
			&nbsp <a href="https://aaronjfisher.github.io/blog_index.html">Blog</a>
			<!-- <a href="https://aaronjfisher.github.io/archives.html"> Archives </a> -->

	      </div>
		<a href="https://aaronjfisher.github.io/index.html" class="title">Aaron Fisher</a>
		<div class="feeds">
          <!--             <a href="https://aaronjfisher.github.io/feeds/all.rss.xml" rel="alternate"><img src="/theme/images/icons/feed-32px.png" alt="rss feed"/></a>
 -->
	    </div>
      </header>
	
	  <div class="wrapper">

		  <div role="main" class="content">

<h1>Research</h1>
<p>For more information, please see my <a href="https://scholar.google.com/citations?user=Ubjcc-IAAAAJ&amp;hl=en" target="_blank">google scholar page</a>.</p>
<h2>Interpretability for machine learning models</h2>
<p>Uninterpretable, black-box prediction models can provoke distrust, and their predictions can be difficult to combine with supplementary information in order to make decisions. In work with <a href="https://users.cs.duke.edu/~cynthia/" target="_blank">Cynthia Rudin</a> and <a href="https://sites.sph.harvard.edu/francesca-dominici/" target="_blank">Francesca Dominici</a>, we pointed out that U-statistics can be used to estimate well-known  variable importance measures, which describe how much a <em>given</em> black-box model uses different covariates to gain prediction accuracy (Breiman <a href="https://link.springer.com/article/10.1023/A:1010933404324" target="_blank">2001a</a>, <a href="https://projecteuclid.org/euclid.ss/1009213726" target=_blank">2001b</a>). We also developed a novel method for estimating how much <em>unknown proprietary</em> models rely on different covariates. Our method optimizes to find several approximations of the proprietary model that function as differently as possible, in terms of how much they rely on each covariate. We applied our method to study the dominant predictive factors in the criminal recidivism model COMPAS. </p>
<ul>
<li><a href="https://arxiv.org/abs/1801.01489" target="_blank">arXiv paper</a>: All Models are Wrong but <em>many</em> are Useful: Variable Importance for Black-Box, Proprietary, or Misspecified Prediction Models, using Model Class Reliance
</br></br></li>
</ul>
<h2>Teaching visual intuition for influence functions</h2>
<p>Statistical analyses often aim to describe a particular attribute (or estimand) of an underlying population distribution, such as the best fitting linear regression line. Influence functions measure how sensitive attributes like these are to changes in the underlying distribution. For example, influence functions can describe how much the best-fitting linear regression model will change if the proportion of points in a particular outlying region increases. Influence functions can also be used to improve estimation efficiency, generating estimators with certain kinds of optimality properties. Unfortunately, and despite their broad applicability, the technical theory underlying influence functions intimidates many researchers away from the subject. </p>
<p>In an <a href="https://arxiv.org/pdf/1810.03260.pdf" target="_blank">educational paper</a> with <a href="http://www.ehkennedy.com" target="_blank">Edward Kennedy</a>, we have tried make this topic more accessible. Our paper is based around two sets of visuals, which, we hope, can be similarly useful to illustrations of a derivative as the “slope at a point,” or illustrations of an integral as the “area under a curve.” For these calculus topics, a guiding intuition can be visualized in minutes, even though formal study typically takes over a semester of coursework.</p>
<p align="center">
<img src="../images/2018-10-01_several_paths.png" alt="PCs+se" style="width: 90%;"/>
</p>

<ul>
<li><a href="https://arxiv.org/pdf/1810.03260.pdf" target="_blank">arXiv paper</a>: Visually Communicating and Teaching Intuition for
Influence Functions
</br></br></li>
</ul>
<h2>Fast, exact bootstrap principal component analysis for high dimensional data (i.e. &gt;1 million variables)</h2>
<p>Principal Component Analysis (PCA) is a common dimension reduction step in many algorithms applied to high dimensional data, where the number of measurements per subject is much greater than the number of subjects. The resulting principal components (PCs) are random test statistics with sampling variability (i.e. if a new sample was recruited, the PCs for the new sample would be different). It is important to estimate this sampling variability, and the extent to which this variability propagates into test statistics that depend on PCA. A bootstrap procedure provides one method for variance estimation, but often comes with a prohibitively heavy computational burden.</p>
<p>To ease this burden, I worked with <a href="http://www.biostat.jhsph.edu/~vzipunni/" target="_blank">Vadim Zipunnikov</a> and <a href="http://www.bcaffo.com" target="_blank">Brian Caffo</a> to develop an exact method for calculating PCs in bootstrap samples that is an order of magnitude faster than the standard method. I applied this method to estimate standard errors of the 3 leading PCs of a brain MRI dataset (≈ 3 million voxels, 352 subjects) based on 1000 bootstrap samples (see below). <em>Computation time was reduced from 4 days to 47 minutes,</em> using a standard laptop. </p>
<p align="center">
<img src="../images/2015-03-20_RAVENS_PCA_saggital_all_approx_legend.png" alt="PCs+se" style="width: 66%;"/>
</p>

<p>The key intuition for this speed improvement comes from the fact that all bootstrap samples are contained in the same n-dimensional subspace as the original sample (where n is the sample size). If we represent bootstrap samples by their n-dimensional coordinates relative to this subspace, we can dramatically reduce computation times and memory requirements.</p>
<ul>
<li><a href="https://www.ncbi.nlm.nih.gov/pubmed/27616801" target="_blank">JASA T&amp;M paper</a> </li>
<li><a href="https://github.com/aaronjfisher/bootSVD" target="_blank">bootSVD R package</a> <img alt="alt text" src="https://cranlogs.r-pkg.org/badges/grand-total/bootSVD" title="download count"> for easy implementation of the bootstrap procedure</li>
<li><a href="https://github.com/aaronjfisher/ggBrain" target="_blank">ggBrain R package</a> for creating brain image figures</li>
</ul>
<p></br></br></p>
<h2>How the effects of interventions vary across individuals</h2>
<p>My previous work on this topic focused on adaptive clinical trials that allow for the possibility of approving an intervention only in a certain subgroup. My ongoing work studies how much variability remains that cannot be mitigated by tailoring the intervention by subgroup. This current work is motivated by studies of air pollution, where many individuals face the same exposure, but some individuals may experience greater harm as a result.</p>
<ul>
<li><a href="https://www.tandfonline.com/doi/abs/10.1080/10543406.2018.1489401" target="_blank">Journal of Biopharmaceutical Statistics paper</a>
</br></br></li>
</ul>
<h2>Evidence based data analysis -- studying statistical methodology in practice</h2>
<p>Much statistical research focuses on the sampling variability of estimators under different theoretical scenarios. However, little is known on the sampling variability that is introduced when human investigators implement analysis methods differently. Knowledge on this human variability could form a key aspect of recommending statistical methods to investigators, and lead to improved reproducibility. <a href="https://peerj.com/articles/589/" target="_blank">In work</a> with <a href="http://jtleek.com/">Jeff Leek</a>, <a href="http://www.cvmbs.colostate.edu/DirectorySearch/Search/MemberProfile/cvmbs/35248/Anderson/Georgiana" target="_blank">G. Brooke Anderson</a>, and <a href="http://www.biostat.jhsph.edu/~rpeng/" target="_blank">Roger Peng</a>, we have proposed the concept of evidence based data analysis: the scientific study of how statistical methods perform in practice, when they are implemented, sometimes imperfectly, by analysts of different levels of statistical training.</p>
<p>In our work, we specifically looked at the common statistical practice of using exploratory data analysis (EDA) to identify significant predictors to include in a model. We conducted a survey in a statistics massive open online course, and asked students to rate the relationships shown in scatterplots as either significant or non-significant at the 0.05 level. Initial rating accuracy was poor, but in some cases improved with practice. Our work sheds light on how fostering statistical literacy can increase the clarity of communication in science, on the effectiveness of EDA for variable selection, and on the extent of damage caused when analysts do not correct for multiple hypotheses that are tested informally in the EDA process.</p>
<p align="center">
<img src="../images/peerj_figure1.jpg" alt="peerJFigure" style="width: 90%;"/>
</br><i>Accuracy with which users can classify relationships that are truly significant (blue) and that are non-significant (red) on their first attempt of the survey. Each row denotes a different presentation style for the scatterplot shown (e.g. whether Lowess trend lines were added). See the <a href="https://peerj.com/articles/589/" target="_blank">full paper</a> for more details.</i>
</p>

<ul>
<li><a href="https://peerj.com/articles/589/" target="_blank">PeerJ Paper</a></li>
<li><a href="../pdfs/2015_jsm_poster_eda.pdf" target="_blank">2015 JSM Poster</a></li>
</ul>
<p></br></br></p>
<h2>Predicting biopsy results and latent health states for patients with low-risk prostate cancer</h2>
<p>For patients with low-risk prostate cancer, prostate biopsies are a highly invasive aspect of active surveillance. I worked with <a href="http://www.rycoley.com/" target="_blank">Yates Coley</a> &amp; <a href="http://www.jhsph.edu/faculty/directory/profile/3859/scott-zeger" target="_blank">Scott Zeger</a> on a <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12577" target="_blank">Bayesian hierarchical model</a> to predict a patient's latent cancer state based on data from previous prostate biopsies and prostate-specific antigen (PSA) measurements. The goal of this modeling approach is to help guide treatment decisions, and to reduce the number of unnecessary biopsies and prostatectomies.</p>
<p>My role in this project was to apply a method for <a href="http://arxiv.org/abs/1510.08802" target="_blank">fast latent state estimation</a> based on new patient data. This would allow doctors to give patients in-clinic risk estimates, without having to refit the entire model with batch MCMC. The proposed method (based on Importance Sampling) does not require novel Bayesian techniques, but it does address one of the obstacles to applying Bayesian Hierarchical models in clinical settings.</p>
<ul>
<li><a href="http://arxiv.org/abs/1510.08802" target="_blank">Technical Report on arXiv</a></li>
<li><a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/biom.12577" target="_blank">Biometrics paper</a></li>
</ul>
<p></br></br></p>		

		  </div>	
		  
		 

	  </div>

      <footer>
		<p role="contentinfo">
            <a href="https://aaronjfisher.github.io/feeds/all.rss.xml" rel="alternate"><img src="/theme/images/icons/feed-18px.png" alt="rss feed"/>RSS</a>.  
          Proudly powered by <a href="http://docs.getpelican.com">pelican</a>. Theme based on <a href="https://github.com/fle/pelican-simplegrey">pelican-simplegrey</a>. 
    	</p>

	  </footer>	

	</div>
	
	  <script>
		var _gaq=[['_setAccount','UA-49475556-1'],['_trackPageview']];
		(function(d,t){var g=d.createElement(t),s=d.getElementsByTagName(t)[0];
		g.src=('https:'==location.protocol?'//ssl':'//www')+'.google-analytics.com/ga.js';
		s.parentNode.insertBefore(g,s)}(document,'script'));
	  </script>

</body>
</html>